---
title: "PSY 504: Bayes Lab 3_2, HMC Diagnostics April 16th, 2025"
format: html
editor: visual
---

This worksheet helps to give you a better idea about what to do with the trace plots.

## Packages and data

Load the primary packages.

```{r, warning = F, message = F}
library(tidyverse)
library(faux)
library(GGally)
library(brms)
library(ggmcmc)
library(bayesplot)
library(ggmcmc)
```

This time we'll simulate data with the **faux** package.

```{r}
# how many cases?
n <- 100

# population values
mu    <- 0
sigma <- 1
rho   <- .5

# simulate and save
set.seed(1)

d <- rnorm_multi(
  n = n,
  mu = c(mu, mu),
  sd = c(sigma, sigma), 
  r = rho, 
  varnames = list("x", "y")
)

glimpse(d)
```

We might look at the data with a `ggpairs()` plot.

```{r}
d %>% 
  ggpairs(diag = list(continuous = wrap("barDiag", binwidth = 0.25)),
          upper = list(continuous = wrap("cor", stars = FALSE)))
```

Check the sample statistics.

```{r}
# univariate
d %>% 
  pivot_longer(everything()) %>% 
  group_by(name) %>% 
  summarise(m = mean(value),
            s = sd(value))

# bivariate
d %>% 
  summarise(r = cor(y, x))
```

## Base model

Let's fit a simple model

$$
\begin{align}
y_i & \sim \operatorname{Normal}(\mu_i, \sigma) \\
\mu_i & = \beta_0 + \beta_1 x_i \\
\beta_0 & \sim \operatorname{Normal}(0, 1) \\
\beta_1 & \sim \operatorname{Normal}(0, 1) \\
\sigma & \sim \operatorname{Exponential}(1),
\end{align}
$$

As we fit the model with `brm()`, take the opportunity to consider some of the default settings.

```{r fit13.b, results = "hide"}
fit13.b <- brm(
  data = d,
  family = gaussian,
  y ~ 1 + x,
  prior = prior(normal(0, 1), class = Intercept) +
    prior(normal(0, 1), class = b) +
    prior(exponential(1), class = sigma),
  seed = 13,
  
  # default settings we've been ignoring up to this point
  iter = 2000, warmup = 1000, chains = 4, cores = 4
  # if you have a good computer, maybe try setting cores = 4
)
```

If you'd like to use multiple cores, but you're not sure how many you have, execute `parallel::detectCores()`.

#### Question 1: How many cores do you have?

10

Check the model summary.

```{r}
summary(fit13.b)
```

Look at the parameter posteriors in a `pairs()` plot.

```{r}
pairs(fit13.b, 
      off_diag_args = list(size = 1/3, alpha = 1/3))
```

The `pairs()` plot is a wrapper around the `mcmc_pairs()` function from **bayesplot**. By default, half of the chains are depicted in the scatter plots below the diagonal, and the other half are displayed above the diagonal. The basic idea is you want the results form different chains to mirror one another. You can control this behavior with the `condition` argument.

```{r}
pairs(fit13.b, 
      off_diag_args = list(size = 1/3, alpha = 1/3),
      # here we put the first chain in above the diagonal,
      # and we put the second through fourth chains below the diagonal
      condition = pairs_condition(chains = list(1, 2:4)))
```

This particular arrangement is a little silly, but it should give you a sense of how to control the output. Also, by default the histograms on the diagonal use the draws from all the chains.

If you wanted, you could also make a similar kind of plot with `ggpairs()`.

```{r, warning = F}
as_draws_df(fit13.b) %>% 
  select(b_Intercept:sigma) %>% 
  ggpairs(diag = list(continuous = wrap("barDiag", bins = 25)),
          upper = list(continuous = wrap("cor", stars = FALSE)),
          lower = list(continuous = wrap("points", size = 1/4, alpha = 1/3)))
```

Now take a look at the `plot()` output.

```{r}
plot(fit13.b, widths = c(1, 2))
```

These trace plots look like a dream. They have the appearance of fuzzy caterpillars, which is why they're even sometimes called *caterpillar plots*.

Let's work directly with the chains via `as_draws_df()`.

```{r}
as_draws_df(fit13.b) %>% 
  # notice the 3 meta-data columns at the end
  glimpse()
```

We can use those meta-data columns to make our own trace plots with **ggplot** functions.

```{r, warning = F}
as_draws_df(fit13.b) %>% 
  pivot_longer(b_Intercept:sigma) %>% 
  mutate(.chain = factor(.chain),
         # not needed, but makes for Greek formatted strip labels
         greek = case_when(
    name == "b_Intercept" ~ "beta[0]",
    name == "b_x"         ~ "beta[1]",
    name == "sigma"       ~ "sigma"
  )) %>% 
  
  ggplot(aes(x = .iteration, y = value, color = .chain)) +
  geom_line(linewidth = 1/3) +
  scale_color_viridis_d(option = "B", end = .9) +
  ggtitle("Hand-made trace plots!") +
  facet_wrap(~ greek, labeller = label_parsed, scales = "free_y")
```

We might restrict to the first few post-warmup iterations to help give us a better sense of what's happening.

```{r, warning = F}
as_draws_df(fit13.b) %>% 
  filter(.iteration < 21) %>% 
  pivot_longer(b_Intercept:sigma) %>% 
  mutate(.chain = factor(.chain),
         # not needed, but makes for nice formatting
         greek = case_when(
    name == "b_Intercept" ~ "beta[0]",
    name == "b_x"         ~ "beta[1]",
    name == "sigma"       ~ "sigma"
  )) %>% 
  
  ggplot(aes(x = .iteration, y = value, color = .chain)) +
  geom_line(linewidth = 1) +
  scale_color_viridis_d(option = "B", end = .9) +
  ggtitle("Hand-made trace plots (zoomed in)") +
  facet_wrap(~ greek, labeller = label_parsed, scales = "free_y")
```

Note that these are all post-warmup draws. The **brms** package doesn't make it easy to visualize the warmup draws. But we can do so with a little help from the **ggmcmc** package's `ggs()` function.

```{r}
# first execute without summarise()
ggs(fit13.b) %>% 
  summarise(min = min(Iteration),
            max = max(Iteration))
```

Note how how the values in the `Iteration` column range from 1 to 2,000. By **brms** default, the first 1,000 of those iterations are the warmup's. Here is how we can use the `ggs()` output to make trace plots that include the warmup draws.

```{r}
ggs(fit13.b) %>% 
  filter(Parameter != "lprior") %>% 
  mutate(Chain = factor(Chain),
         greek = case_when(
    Parameter == "b_Intercept" ~ "beta[0]",
    Parameter == "b_x"         ~ "beta[1]",
    Parameter == "sigma"       ~ "sigma"
  )) %>% 
  
  ggplot(aes(x = Iteration, y = value, color = Chain)) +
  # this marks off the warmups
  annotate(geom = "rect", 
           xmin = 0, xmax = 1000, ymin = -Inf, ymax = Inf,
           fill = "black", alpha = 1/6, linewidth = 0) +
  geom_line(linewidth = 1/3) +
  scale_color_viridis_d(option = "B", end = .9) +
  labs(title = "More hand-made trace plots",
       subtitle = "warmup/post-warmup by background") +
  facet_wrap(~ greek, labeller = label_parsed, scales = "free_y")
```

Let's take a closer look at the first few warmup iterations.

```{r}
ggs(fit13.b) %>% 
  filter(Parameter != "lprior") %>% 
  mutate(Chain = factor(Chain),
         greek = case_when(
    Parameter == "b_Intercept" ~ "beta[0]",
    Parameter == "b_x"         ~ "beta[1]",
    Parameter == "sigma"       ~ "sigma"
  )) %>% 
  
  ggplot(aes(x = Iteration, y = value, color = Chain)) +
  annotate(geom = "rect", 
           xmin = 0, xmax = 1000, ymin = -Inf, ymax = Inf,
           fill = "black", alpha = 1/6, linewidth = 0) +
  geom_line(linewidth = 2/3) +
  scale_color_viridis_d(option = "B", end = .9) +
  coord_cartesian(xlim = c(0, 50)) +
  labs(title = "More hand-made trace plots (zoomed in)",
       subtitle = "warmup only") +
  facet_wrap(~ greek, labeller = label_parsed, scales = "free_y")
```

#### Question 2: Can you use the results here to describe the need for discarding warmup draws?

*Visual evidence from the trace plots*\
In the first iterations the chains **drift quickly** toward the high-density region of the posterior and the step-size/mass-matrix are being tuned. After that the traces flatten into the familiar “fuzzy-caterpillar” look.

Hence we discard the warm-up draws.

Another issue is *autocorrelation*, the degree to which a given HMC draw is correlated with the previous draw(s). We can make a plot of the autocorrelations with the `mcmc_acf()` function from the **bayesplot** package.

```{r}
fit13.b %>% 
  mcmc_acf(pars = vars(b_Intercept, b_x, sigma),
           lags = 10)  # lags = 20 is the default
```

This is what we like to see: Nice L-shaped autocorrelation plots. Low autocorrelations like this are one of the major achievements of Stan's implementation of HMC. It's not uncommon for MCMC via the older Gibbs sampler method to routinely show much higher autocorrelations. You can get a sense of this by comparing the various models in Kruschke's (2015) textbook, which often uses the Gibbs sampler, versus their `brms()` analogues in my (2023) ebook translation.

::: callout-note
Mixing describes how efficiently MCMC chains explore the posterior distribution. Good mixing means samples move freely across the parameter space. And high autocorrelation =\> poor mixing.
:::

#### Question 3: Why are L-shaped autocorrelation plots are desirable? What would an undesirable autocorrelation plot look like?

A sharp drop off (L-shape) means that consecutive draws are *nearly independent*; the chain forgets its previous position after just a step or two.

A undesirable plot would have for example a slowly decaying tail or positive spikes across many lags; sometimes oscillatory patterns.

```{r}
summary(fit13.b)
```

There used to be a single ESS column. Starting with version 2.10.0, **brms** returns two columns: `Bulk_ESS` and `Tail_ESS`. These originate from Vehtari et al (2019). From the paper, we read:

> When reporting quantile estimates or posterior intervals, we strongly suggest assessing the convergence of the chains for these quantiles. In Section 4.3, we show that convergence of Markov chains is not uniform across the parameter space, that is, convergence might be different in the bulk of the distribution (e.g., for the mean or median) than in the tails (e.g., for extreme quantiles). We propose diagnostics and effective sample sizes specifically for extreme quantiles. This is different from the standard ESS estimate (which we refer to as bulk-ESS), which mainly assesses how well the centre of the distribution is resolved. Instead, these "tail-ESS" measures allow the user to estimate the MCSE for interval estimates. (pp. 672-673)

We generally like the values in both the `Bulk_ESS` and `Tail_ESS` columns to be as close to the total number of post-warmup draws as possible, which would be 4,000 for a default `brm()` model. Sometimes, as in the case of the `Bulk_ESS` value for our $\beta_1$ parameter, the HMC chains are so efficient that we can get larger numbers than the actual number of post-warmup draws. This is related to when we have negative autocorrelations (see above).

How much is enough, and how low is too low? Yeah, indeed... Higher is generally better, with diminishing returns rolling in somewhere between 1,000 and 10,000. **brms** will give you a warning message when the ESS estimates get below a couple hundred.

Now look back at the `Rhat` column in the `summary()` output. This is the potential scale reduction factor $\hat R$. It has its origins in Gelman & Rubin (1992), but the current version used in **brms** is from Vehtari et al (2019), as cited above. In short, it is something of a ratio of the between-chain variation versus the within-chain variation. This ratio is usually a little above 1, and we want it to be as close to 1 as possible. The Stan team (e.g., <https://mc-stan.org/rstan/reference/Rhat.html)> recommends against values greater than 1.05. In our case, we're good to go.

## What bad chains look like..

Now let's break the model. This time, we'll subset the `d` data to just the first 2 rows, we'll make the priors very wide on the scale of the data, and we'll dramatically reduce the `warmup` period.

```{r fit14.b, results = "hide"}
fit14.b <- brm(
  data = d %>% slice(1:2),
  family = gaussian,
  y ~ 1 + x,
  # don't use priors like this for real data analyses
  prior = prior(normal(0, 100000), class = Intercept) +
    prior(normal(0, 100000), class = b) +
    prior(uniform(0, 100000), class = sigma),
  seed = 14,
  iter = 1100, warmup = 100, chains = 4, cores = 4
)
```

Check the parameter summary.

```{r}
print(fit14.b)
```

Never ignore Warning messages like that.

Those `Rhat`, `Bulk_ESS`, and `Tail_ESS` look really bad. Also notice how large the posterior means (`Estimate`) and standard deviations (`Est.Error`) are. Seems off, eh?

Let's investigate further with a `pairs()` plot.

```{r}
plot(fit14.b, widths = c(1, 2))
```

This is a full-scale disaster. DO NOT trust model results from chains that look like this.

In this case, just giving the model a longer `warmup` period helped a lot.

```{r fit15.b, results = "hide"}
fit15.b <- brm(
  data = d %>% slice(1:2),
  family = gaussian,
  y ~ 1 + x,
  # don't use priors like this in real life
  prior = prior(normal(0, 100000), class = Intercept) +
    prior(normal(0, 100000), class = b) +
    prior(uniform(0, 100000), class = sigma),
  seed = 14,
  iter = 2000, warmup = 1000, chains = 4, cores = 4
)
```

```{r}
plot(fit15.b, widths = c(1, 2))
```

We still have a lot of Warning messages, but things have improved.

We can do an even better with default weakly-regularizing priors.

```{r fit16.b, results = "hide"}
fit16.b <- brm(
  data = d %>% slice(1:2),
  family = gaussian,
  y ~ 1 + x,
  prior = prior(normal(0, 1), class = Intercept) +
    prior(normal(0, 1), class = b) +
    prior(exponential(1), class = sigma),
  seed = 14,
  iter = 2000, warmup = 1000, chains = 4, cores = 4
)
```

```{r}
plot(fit16.b, widths = c(1, 2))
```

Now look at the parameter summaries.

```{r}
print(fit16.b)
```

Those Warning messages still remain, but they're less dire than before. Also, most of the other diagnostics look better. I still wouldn't trust this model. It is only based on 2 data points, after all. But look how far we got by paying attention to the diagnostics and picking better priors.

## References

Gelman, A. and Rubin, D. (1992). Inference from iterative simulation using multiple sequences. *Statistical Science, 7*(4):457–472. <https://dx.doi.org/10.1214/ss/1177011136>

Kruschke, J. K. (2015). *Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan*. Academic Press. <https://sites.google.com/site/doingbayesiandataanalysis/>

Kurz, A. S. (2023). *Doing Bayesian data analysis in brms and the tidyverse* (Version 1.1.0). <https://bookdown.org/content/3686/>

McElreath, R. (2020). *Statistical rethinking: A Bayesian course with examples in R and Stan* (Second Edition). CRC Press. <https://xcelab.net/rm/statistical-rethinking/>

Vehtari, A., Gelman, A., Simpson, D., Carpenter, B., & Bürkner, P.-C. (2019). Rank-normalization, folding, and localization: An improved $\widehat R$ for assessing convergence of MCMC (with discussion). *Bayesian Analysis, 16*(2), 667-718. <https://doi.org/10.1214/20-BA1221>

## Session information

```{r}
sessionInfo()
```